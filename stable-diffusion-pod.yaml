# Save the output of this file and use kubectl create -f to import
# it into Kubernetes.
#
# Created with podman-5.2.1
apiVersion: v1
kind: Pod
metadata:
  annotations:
    io.kubernetes.cri-o.SandboxID/stable-diffusion-automatic1111: 133c14fffbdb8e1005be9f1a75f168d529492d75efa5b7b35a5e3ef01648d50d
    io.kubernetes.cri-o.SandboxID/stable-diffusion-comfy: 133c14fffbdb8e1005be9f1a75f168d529492d75efa5b7b35a5e3ef01648d50d
    io.kubernetes.cri-o.SandboxID/stable-diffusion-download: 133c14fffbdb8e1005be9f1a75f168d529492d75efa5b7b35a5e3ef01648d50d
    io.kubernetes.cri-o.SandboxID/stable-diffusion-invoke: 133c14fffbdb8e1005be9f1a75f168d529492d75efa5b7b35a5e3ef01648d50d
  creationTimestamp: "2024-08-23T12:47:25Z"
  labels:
    app: stable-diffusion-webuis
  name: stable-diffusion-webuis
spec:
  containers:
  - image: localhost/stable-diffusion-download:latest
    name: container-download
    volumeMounts:
    - mountPath: /data
      name: volume-data
    tty: true
    devices:
    - nvidia.com/gpu=all
  - args:
    - /bin/sh
    - -c
    - python -u webui.py --listen --port 7860 ${CLI_ARGS}
    image: localhost/stable-diffusion-automatic1111:latest
    name: container-automatic1111
    volumeMounts:
    - mountPath: /data
      name: volume-data
    - mountPath: /output
      name: volume-output
    ports:
    - containerPort: 7860
      hostPort: 7860
    env:
    - name: CLI_ARGS
      value: "--allow-code --medvram --xformers --enable-insecure-extension-access --api"
    tty: true
    devices:
    - nvidia.com/gpu=all
  - args:
    - /bin/sh
    - -c
    - invokeai --web --host 0.0.0.0 --port 7861 --root_dir ${ROOT} --config ${CONFIG_DIR}/models.yaml     --outdir
      /output/invoke --embedding_directory /data/embeddings/ --lora_directory /data/models/Lora     --no-nsfw_checker
      --no-safety_checker ${CLI_ARGS}
    image: localhost/stable-diffusion-invoke:latest
    name: container-invoke
    volumeMounts:
    - mountPath: /data
      name: volume-data
    - mountPath: /output
      name: volume-output
    ports:
    - containerPort: 7861
      hostPort: 7861
    env:
    - name: CLI_ARGS
      value: "--xformers"
    - name: PRELOAD
      value: true
    tty: true
    devices:
    - nvidia.com/gpu=all
  - args:
    - /bin/sh
    - -c
    - python -u main.py --listen --port 7862 ${CLI_ARGS}
    image: localhost/stable-diffusion-comfy:latest
    name: container-comfy
    volumeMounts:
    - mountPath: /output
      name: volume-output
    - mountPath: /data
      name: volume-data
    ports:
    - containerPort: 7862
      hostPort: 7862
    env:
    - name: CLI_ARGS
      value: ""
    tty: true
    devices:
    - nvidia.com/gpu=all
  volumes:
  - hostPath:
      path: /opt/stable-diffusion-webui-podman/data
      type: Directory
    name: volume-data
  - hostPath:
      path: /opt/stable-diffusion-webui-podman/output
      type: Directory
    name: volume-output
